{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hello\n\nThis notebook is inspired from \"Lightgbm(Regressor) | Kaggle\" kernel.\nhttps://www.kaggle.com/hiro5299834/wifi-features-with-lightgbm-kfold\n\n\nI am studying Machine Learning and I was requested to participate to one competition of my choise on Kaggle.\nSo I am doing it as an exercice.\nPlease be indulgent.\nMy plan here is to capture all the big steps in the process of machine learning modeling and to test some specific models that are not yet used by other kernels on this competition.\n\nMy first thought is to test Xgboost since the primary Kernel I am inspiring on is using Lightgbm model.\n\nI will test another model later on.\n\nFor the exploratory step I have been inspired by these notebooks:\n- https://www.kaggle.com/chandrylpaternetony/data-descript-outlier-detect-floor-mapping\n\n- https://www.kaggle.com/ihelon/indoor-location-exploratory-data-analysis/notebook\n"},{"metadata":{},"cell_type":"markdown","source":"Quick overview of the input data structure"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(f\"Number of train sites {len(os.listdir('../input/indoor-location-navigation/train/'))}\")\nprint(f\"Number of train meta {len(os.listdir('../input/indoor-location-navigation/metadata/'))}\")\nprint(f\"Number of test sites {len(os.listdir('../input/indoor-location-navigation/test/'))}\")","execution_count":11,"outputs":[{"output_type":"stream","text":"Number of train sites 204\nNumber of train meta 204\nNumber of test sites 626\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\ninput_data_structure = list()\nfor site in os.listdir('../input/indoor-location-navigation/train/'):\n    for floor in os.listdir('../input/indoor-location-navigation/train/' + site + '/'):\n        for phone in os.listdir('../input/indoor-location-navigation/train/' + site + '/' + floor + '/'):\n            input_data_structure.append([site,floor,phone])\nprint(len(input_data_structure))            \n                                        ","execution_count":12,"outputs":[{"output_type":"stream","text":"26925\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Conversion into pandas DataFrame for quick statistics over the input data files"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ninput_df = pd.DataFrame(input_data_structure, columns=['sites','floor','phone'])\ninput_df.describe(include=\"all\")","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"                           sites  floor                         phone\ncount                      26925  26925                         26925\nunique                       204     43                         26925\ntop     5d27075f03f801723c2e360f     F1  5d60ad2404ffc90008edf43d.txt\nfreq                        1141   4557                             1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sites</th>\n      <th>floor</th>\n      <th>phone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>26925</td>\n      <td>26925</td>\n      <td>26925</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>204</td>\n      <td>43</td>\n      <td>26925</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>5d27075f03f801723c2e360f</td>\n      <td>F1</td>\n      <td>5d60ad2404ffc90008edf43d.txt</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1141</td>\n      <td>4557</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"* There are **204** different **sites**\n* There are **43!!!** different **floors** identification, be aware F1 or 1F is the same floor. So we obviously have less then 43 different floors\n* there are **26925** different **phones** and every phone has only one single recording and has been recording at the same floor\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = pd.pivot_table(input_df, values=['phone'], index=['sites','floor'], margins=True,\n                    aggfunc={\"phone\": \"count\"})\nprint(table)","execution_count":14,"outputs":[{"output_type":"stream","text":"                                phone\nsites                    floor       \n5a0546857ecc773753327266 B1       109\n                         F1       131\n                         F2       110\n                         F3        78\n                         F4        86\n...                               ...\n5dc8cea7659e181adb076a3f F4        79\n                         F5       103\n                         F6        81\n                         F7        40\nAll                             26925\n\n[982 rows x 1 columns]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"table.describe(include = \"all\")","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"              phone\ncount    982.000000\nmean      54.837067\nstd      859.103814\nmin        1.000000\n25%        6.000000\n50%       14.000000\n75%       31.000000\nmax    26925.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>phone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>982.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>54.837067</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>859.103814</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>14.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>26925.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"table_floor = pd.pivot_table(input_df, values=['floor'], index=['sites'], margins=True,\n                    aggfunc={\"floor\": \"count\"})\nprint(table_floor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(table_floor.index[:-1],table_floor['floor'][:-1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will focus on Wifi features.\nWe will take for granted the preprocessing of input data **indoor-location-navigation** and its transformation into **indoor-navigation-and-location-wifi-features**\n\nAbout this Dataset\nContent\nVersion2 update:\nContains features for the indoor location and navigation competition. They were based on \"Indoor Navigation and Location Wifi Features\" data by @devinanzelmo and generated using only wifi's bssid in the training dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(f\"Number of csv inputs {len(os.listdir('../input/indoor-navigation-and-location-wifi-features/'))}\")","execution_count":16,"outputs":[{"output_type":"stream","text":"Number of csv inputs 48\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"import xgboost as xgb\n\nxgb_params = {'max_depth':2, 'eta':1, 'objective':'reg:squarederror', 'eval_metric':'rmse', 'seed': SEED }\n\n# using scikit learn API\n\n''' lgb_params = {'objective': 'root_mean_squared_error',\n              'boosting_type': 'gbdt',\n              'n_estimators': 50000,\n              'learning_rate': 0.1,\n              'num_leaves': 90,\n              'colsample_bytree': 0.4,\n              'subsample': 0.6,\n              'subsample_freq': 2,\n              'bagging_seed': SEED,\n              'reg_alpha': 8,\n              'reg_lambda': 2,\n              'random_state': SEED,\n              'n_jobs': -1\n              }\n'''\nxgb_params = {'objective': 'root_mean_squared_error',\n              'booster': 'gbtree',\n              'n_estimators': 50000,\n              'learning_rate': 0.1,              \n              'reg_alpha': 8,\n              'reg_lambda': 2,\n              'random_state': SEED,\n              'n_jobs': -1\n              }\n\n# classifier\n'''\nxgb_f_params = {'objective': 'multiclass',\n                'booster': 'gbtree',\n                'n_estimators': 50000,\n                'learning_rate': 0.1,                \n                'reg_alpha': 10,\n                'reg_lambda': 2,\n                'random_state': SEED,\n                'n_jobs': -1\n                }\n                '''\n\nParameters\nn_estimators (int) – Number of boosting rounds.\n\nuse_label_encoder (bool) – (Deprecated) Use the label encoder from scikit-learn to encode the labels. For new code, we recommend that you set this parameter to False.\n\nmax_depth (int) – Maximum tree depth for base learners.\n\nlearning_rate (float) – Boosting learning rate (xgb’s “eta”)\n\nverbosity (int) – The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n\nobjective (string or callable) – Specify the learning task and the corresponding learning objective or a custom objective function to be used (see note below).\n\nbooster (string) – Specify which booster to use: gbtree, gblinear or dart.\n\ntree_method (string) – Specify which tree method to use. Default to auto. If this parameter is set to default, XGBoost will choose the most conservative option available. It’s recommended to study this option from parameters document.\n\nn_jobs (int) – Number of parallel threads used to run xgboost. When used with other Scikit-Learn algorithms like grid search, you may choose which algorithm to parallelize and balance the threads. Creating thread contention will significantly slow down both algorithms.\n\ngamma (float) – Minimum loss reduction required to make a further partition on a leaf node of the tree.\n\nmin_child_weight (float) – Minimum sum of instance weight(hessian) needed in a child.\n\nmax_delta_step (float) – Maximum delta step we allow each tree’s weight estimation to be.\n\nsubsample (float) – Subsample ratio of the training instance.\n\ncolsample_bytree (float) – Subsample ratio of columns when constructing each tree.\n\ncolsample_bylevel (float) – Subsample ratio of columns for each level.\n\ncolsample_bynode (float) – Subsample ratio of columns for each split.\n\nreg_alpha (float (xgb's alpha)) – L1 regularization term on weights\n\nreg_lambda (float (xgb's lambda)) – L2 regularization term on weights\n\nscale_pos_weight (float) – Balancing of positive and negative weights.\n\nbase_score – The initial prediction score of all instances, global bias.\n\nrandom_state (int) –\n\nRandom number seed."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nsubm = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv', index_col=0)\nsubm.describe(include='all')","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"         floor        x        y\ncount  10133.0  10133.0  10133.0\nmean       0.0     75.0     75.0\nstd        0.0      0.0      0.0\nmin        0.0     75.0     75.0\n25%        0.0     75.0     75.0\n50%        0.0     75.0     75.0\n75%        0.0     75.0     75.0\nmax        0.0     75.0     75.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>floor</th>\n      <th>x</th>\n      <th>y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10133.0</td>\n      <td>10133.0</td>\n      <td>10133.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"../input/indoor-navigation-and-location-wifi-features/5a0546857ecc773753327266_train.csv","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"4"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = pd.read_csv('../input/indoor-navigation-and-location-wifi-features/5a0546857ecc773753327266_test.csv',index_col=0)\n# df = pd.read_csv('../input/indoor-navigation-and-location-wifi-features/5a0546857ecc773753327266_train.csv',index_col=0)\n# df = pd.read_csv('../input/indoor-navigation-and-location-wifi-features/5da138314db8ce0c98bbf3a0_train.csv',index_col=0)\ndf = pd.read_csv('../input/indoor-navigation-and-location-wifi-features/5d2709a003f801723c3251bf_train.csv',index_col=0)\n\ndf.iloc[:10,-4:]","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"           x          y  f                      path\n4  157.05070  45.583950  0  5dbbd0665da9ed000681635c\n4  157.05070  45.583950  0  5dbbd0665da9ed000681635c\n4  157.05070  45.583950  0  5dbbd0665da9ed000681635c\n4  152.21686  50.334830  0  5dbbd0665da9ed000681635c\n4  152.21686  50.334830  0  5dbbd0665da9ed000681635c\n4  152.21686  50.334830  0  5dbbd0665da9ed000681635c\n4  152.21686  50.334830  0  5dbbd0665da9ed000681635c\n4  152.21686  50.334830  0  5dbbd0665da9ed000681635c\n4  152.21686  50.334830  0  5dbbd0665da9ed000681635c\n4  151.03008  46.102364  0  5dbbd0665da9ed000681635c","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>f</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>157.05070</td>\n      <td>45.583950</td>\n      <td>0</td>\n      <td>5dbbd0665da9ed000681635c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>157.05070</td>\n      <td>45.583950</td>\n      <td>0</td>\n      <td>5dbbd0665da9ed000681635c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>157.05070</td>\n      <td>45.583950</td>\n      <td>0</td>\n      <td>5dbbd0665da9ed000681635c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>152.21686</td>\n      <td>50.334830</td>\n      <td>0</td>\n      <td>5dbbd0665da9ed000681635c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>152.21686</td>\n      <td>50.334830</td>\n      <td>0</td>\n      <td>5dbbd0665da9ed000681635c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>152.21686</td>\n      <td>50.334830</td>\n      <td>0</td>\n      <td>5dbbd0665da9ed000681635c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>152.21686</td>\n      <td>50.334830</td>\n      <td>0</td>\n      <td>5dbbd0665da9ed000681635c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>152.21686</td>\n      <td>50.334830</td>\n      <td>0</td>\n      <td>5dbbd0665da9ed000681635c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>152.21686</td>\n      <td>50.334830</td>\n      <td>0</td>\n      <td>5dbbd0665da9ed000681635c</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>151.03008</td>\n      <td>46.102364</td>\n      <td>0</td>\n      <td>5dbbd0665da9ed000681635c</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# testing XGBOOST classifier settings\n# ------------------------------------------------------------------------------\n# Import libraries\n# ------------------------------------------------------------------------------\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nfrom pathlib import Path\nimport glob\n\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\n\nimport psutil\nimport random\nimport os\nimport time\nimport sys\nimport math\nfrom contextlib import contextmanager\n\n\n\n\n\n# ------------------------------------------------------------------------------\n# Fixed values\n# ------------------------------------------------------------------------------\nN_SPLITS = 10\nSEED = 42\n\n# ------------------------------------------------------------------------------\n# File path definition\n# ------------------------------------------------------------------------------\nLOG_PATH = Path(\"./log/\")\nLOG_PATH.mkdir(parents=True, exist_ok=True)\n\n\n# ------------------------------------------------------------------------------\n# Utilities\n# ------------------------------------------------------------------------------\n@contextmanager\ndef timer(name: str):\n    t0 = time.time()\n    p = psutil.Process(os.getpid())\n    m0 = p.memory_info()[0] / 2. ** 30\n    try:\n        yield\n    finally:\n        m1 = p.memory_info()[0] / 2. ** 30\n        delta = m1 - m0\n        sign = '+' if delta >= 0 else '-'\n        delta = math.fabs(delta)\n        print(f\"[{m1:.1f}GB({sign}{delta:.1f}GB): {time.time() - t0:.3f}sec] {name}\", file=sys.stderr)\n\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n\n    \ndef comp_metric(xhat, yhat, fhat, x, y, f):\n    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n    return intermediate.sum()/xhat.shape[0]\n\n\ndef score_log(df: pd.DataFrame, num_files: int, nam_file: str, data_shape: tuple, n_fold: int, seed: int, mpe: float):\n    score_dict = {'n_files': num_files, 'file_name': nam_file, 'shape': data_shape, 'fold': n_fold, 'seed': seed, 'score': mpe}\n    # noinspection PyTypeChecker\n    df = pd.concat([df, pd.DataFrame.from_dict([score_dict])])\n    df.to_csv(LOG_PATH / f\"log_score.csv\", index=False)\n    return df\n\n\n\n\n# ------------------------------------------------------------------------------\n# Set seed\n# ------------------------------------------------------------------------------\nset_seed(SEED)\n\n# ------------------------------------------------------------------------------\n# Read data\n# ------------------------------------------------------------------------------\nfeature_dir = \"../input/indoor-navigation-and-location-wifi-features\"\ntrain_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\ntest_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\nsubm = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv', index_col=0)\n\n# ------------------------------------------------------------------------------\n# Define parameters for models\n# ------------------------------------------------------------------------------\n\n# add settings for xgboost\nxgb_params = {'objective': 'reg:squarederror',\n              'booster': 'gbtree',\n              'n_estimators': 1000,\n              'learning_rate': 0.1,              \n              'reg_alpha': 8,\n              'reg_lambda': 2,\n              'random_state': SEED,\n              'n_jobs': -1\n              }\n\n# /opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated \n# and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False\n# when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n# use_label_encoder: False required encode of interger type!!! from 0 to num_class-1\n# WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n# AHM UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n# error removed with 'multi:softmax'\nxgb_f_params = {'objective': 'multi:softmax', #multi:softmax  multi:softprob\n                'booster': 'gbtree',               \n                'n_estimators': 1000,\n                'learning_rate': 0.1,                \n                'reg_alpha': 10,\n                'reg_lambda': 2,\n                'random_state': SEED, #'use_label_encoder':False,                \n                'n_jobs': -1\n                }\n# ------------------------------------------------------------------------------\n# Training and inference\n# ------------------------------------------------------------------------------\nscore_df = pd.DataFrame()\noof = list()\npredictions = list()\nfor n_files, file in enumerate(train_files):\n    data = pd.read_csv(file, index_col=0)\n    # trick here is to use one single loop to parse both training and validation files\n    test_data = pd.read_csv(test_files[n_files], index_col=0)\n\n    oof_x, oof_y, oof_f = np.zeros(data.shape[0]), np.zeros(data.shape[0]), np.zeros(data.shape[0])\n    preds_x, preds_y = 0, 0\n    preds_f_arr = np.zeros((test_data.shape[0], N_SPLITS))\n\n    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n    for fold, (trn_idx, val_idx) in enumerate(kf.split(data.iloc[:, :-4])):\n        X_train = data.iloc[trn_idx, :-4]\n        y_trainx = data.iloc[trn_idx, -4]\n        y_trainy = data.iloc[trn_idx, -3]\n        y_trainf = data.iloc[trn_idx, -2]\n\n        X_valid = data.iloc[val_idx, :-4]\n        y_validx = data.iloc[val_idx, -4]\n        y_validy = data.iloc[val_idx, -3]\n        y_validf = data.iloc[val_idx, -2]\n\n\n        # modelf = lgb.LGBMClassifier(**lgb_f_params)\n        # remove param eval_metric='multi_logloss', for xgb\n        modelf = xgb.XGBClassifier(**xgb_f_params)\n        with timer(\"fit F\"):\n            modelf.fit(X_train, y_trainf,\n                       eval_set=[(X_valid, y_validf)],\n                       eval_metric='mlogloss', #for xgboot\n                       verbose=False,\n                       early_stopping_rounds=20\n                       )\n\n      \n        oof_f[val_idx] = modelf.predict(X_valid).astype(int)\n\n       \n        preds_f_arr[:, fold] = modelf.predict(test_data.iloc[:, :-1]).astype(int)\n        break\n       # score = comp_metric(oof_x[val_idx], oof_y[val_idx], oof_f[val_idx],\n       #                     y_validx.to_numpy(), y_validy.to_numpy(), y_validf.to_numpy())\n       # print(f\"fold {fold}: mean position error {score}\")\n       # score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, fold, SEED, score)\n\n    print(\"*+\"*40)\n    print(f\"file #{n_files}, shape={data.shape}, name={os.path.basename(file)}\")\n    print(\"oof_f shape : \", oof_f.shape)\n    print(\"preds_f_arr \", preds_f_arr.shape)\n    print(\"*+\"*40)\n    \n\n    preds_f_mode = stats.mode(preds_f_arr, axis=1)\n    preds_f = preds_f_mode[0].astype(int).reshape(-1)\n    test_preds = pd.DataFrame(np.stack((preds_f, preds_x, preds_y))).T\n    test_preds.columns = subm.columns\n    test_preds.index = test_data[\"site_path_timestamp\"]\n    test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n    predictions.append(test_preds)\n    break\n\n'''\n\n# ------------------------------------------------------------------------------\n# Submit the result\n# ------------------------------------------------------------------------------\nall_preds = pd.concat(predictions)\nall_preds = all_preds.reindex(subm.index)\nall_preds.to_csv('submission.csv')\nprint(\"*+\"*40)\nprint('End')\nprint(\"*+\"*40)\n\n'''"},{"metadata":{"_uuid":"96bb8a60-72bc-4b0b-8798-795dfda98988","_cell_guid":"4921258f-5532-44da-b9da-4e920592a368","trusted":true},"cell_type":"code","source":"# ------------------------------------------------------------------------------\n# Import libraries\n# ------------------------------------------------------------------------------\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as stats\nfrom pathlib import Path\nimport glob\n\nfrom sklearn.model_selection import KFold\nimport lightgbm as lgb\nimport xgboost as xgb\n\nimport psutil\nimport random\nimport os\nimport time\nimport sys\nimport math\nfrom contextlib import contextmanager\n\n\n\n\n\n# ------------------------------------------------------------------------------\n# Fixed values\n# ------------------------------------------------------------------------------\nN_SPLITS = 10\nSEED = 42\n\n# ------------------------------------------------------------------------------\n# File path definition\n# ------------------------------------------------------------------------------\nLOG_PATH = Path(\"./log/\")\nLOG_PATH.mkdir(parents=True, exist_ok=True)\n\n\n# ------------------------------------------------------------------------------\n# Utilities\n# ------------------------------------------------------------------------------\n@contextmanager\ndef timer(name: str):\n    t0 = time.time()\n    p = psutil.Process(os.getpid())\n    m0 = p.memory_info()[0] / 2. ** 30\n    try:\n        yield\n    finally:\n        m1 = p.memory_info()[0] / 2. ** 30\n        delta = m1 - m0\n        sign = '+' if delta >= 0 else '-'\n        delta = math.fabs(delta)\n        print(f\"[{m1:.1f}GB({sign}{delta:.1f}GB): {time.time() - t0:.3f}sec] {name}\", file=sys.stderr)\n\n\ndef set_seed(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n\n    \ndef comp_metric(xhat, yhat, fhat, x, y, f):\n    intermediate = np.sqrt(np.power(xhat-x, 2) + np.power(yhat-y, 2)) + 15 * np.abs(fhat-f)\n    return intermediate.sum()/xhat.shape[0]\n\n\ndef score_log(df: pd.DataFrame, num_files: int, nam_file: str, data_shape: tuple, n_fold: int, seed: int, mpe: float):\n    score_dict = {'n_files': num_files, 'file_name': nam_file, 'shape': data_shape, 'fold': n_fold, 'seed': seed, 'score': mpe}\n    # noinspection PyTypeChecker\n    df = pd.concat([df, pd.DataFrame.from_dict([score_dict])])\n    df.to_csv(LOG_PATH / f\"log_score.csv\", index=False)\n    return df\n\n\n\n\n# ------------------------------------------------------------------------------\n# Set seed\n# ------------------------------------------------------------------------------\nset_seed(SEED)\n\n# ------------------------------------------------------------------------------\n# Read data\n# ------------------------------------------------------------------------------\nfeature_dir = \"../input/indoor-navigation-and-location-wifi-features\"\ntrain_files = sorted(glob.glob(os.path.join(feature_dir, '*_train.csv')))\ntest_files = sorted(glob.glob(os.path.join(feature_dir, '*_test.csv')))\nsubm = pd.read_csv('../input/indoor-location-navigation/sample_submission.csv', index_col=0)\n\n# ------------------------------------------------------------------------------\n# Define parameters for models\n# ------------------------------------------------------------------------------\nlgb_params = {'objective': 'root_mean_squared_error',\n              'boosting_type': 'gbdt',\n              'n_estimators': 50000,\n              'learning_rate': 0.1,\n              'num_leaves': 90,\n              'colsample_bytree': 0.4,\n              'subsample': 0.6,\n              'subsample_freq': 2,\n              'bagging_seed': SEED,\n              'reg_alpha': 8,\n              'reg_lambda': 2,\n              'random_state': SEED,\n              'n_jobs': -1\n              }\n# add settings for xgboost\nxgb_params = {'objective': 'reg:squarederror',\n              'booster': 'gbtree',\n              'n_estimators': 1000,\n              'learning_rate': 0.1,              \n              'reg_alpha': 8,\n              'reg_lambda': 2,\n              'random_state': SEED,\n              'n_jobs': -1\n              }\n\nlgb_f_params = {'objective': 'multiclass',\n                'boosting_type': 'gbdt',\n                'n_estimators': 50000,\n                'learning_rate': 0.1,\n                'num_leaves': 90,\n                'colsample_bytree': 0.4,\n                'subsample': 0.6,\n                'subsample_freq': 2,\n                'bagging_seed': SEED,\n                'reg_alpha': 10,\n                'reg_lambda': 2,\n                'random_state': SEED,\n                'n_jobs': -1\n                }\n# WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n# UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n\nxgb_f_params = {'objective': 'multi:softmax', #multi:softmax  multi:softprob, will require use of encoder of type integer\n                'booster': 'gbtree',               \n                'n_estimators': 1000,\n                'learning_rate': 0.1,                \n                'reg_alpha': 10,\n                'reg_lambda': 2,\n                'random_state': SEED,                \n                'n_jobs': -1\n                }\n# ------------------------------------------------------------------------------\n# Training and inference\n# ------------------------------------------------------------------------------\nscore_df = pd.DataFrame()\noof = list()\npredictions = list()\nfor n_files, file in enumerate(train_files):\n    data = pd.read_csv(file, index_col=0)\n    test_data = pd.read_csv(test_files[n_files], index_col=0)\n\n    oof_x, oof_y, oof_f = np.zeros(data.shape[0]), np.zeros(data.shape[0]), np.zeros(data.shape[0])\n    preds_x, preds_y = 0, 0\n    preds_f_arr = np.zeros((test_data.shape[0], N_SPLITS))\n\n    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n    for fold, (trn_idx, val_idx) in enumerate(kf.split(data.iloc[:, :-4])):\n        X_train = data.iloc[trn_idx, :-4]\n        y_trainx = data.iloc[trn_idx, -4]\n        y_trainy = data.iloc[trn_idx, -3]\n        y_trainf = data.iloc[trn_idx, -2]\n\n        X_valid = data.iloc[val_idx, :-4]\n        y_validx = data.iloc[val_idx, -4]\n        y_validy = data.iloc[val_idx, -3]\n        y_validf = data.iloc[val_idx, -2]\n\n        # modelx = lgb.LGBMRegressor(**lgb_params)\n        modelx = xgb.XGBRegressor(**xgb_params)\n        with timer(\"fit X\"):\n            modelx.fit(X_train, y_trainx,\n                       eval_set=[(X_valid, y_validx)],\n                       eval_metric='rmse',\n                       verbose=False,\n                       early_stopping_rounds=20\n                      )\n\n        # modely = lgb.LGBMRegressor(**lgb_params)\n        modely = xgb.XGBRegressor(**xgb_params)\n        with timer(\"fit Y\"):\n            modely.fit(X_train, y_trainy,\n                       eval_set=[(X_valid, y_validy)],\n                       eval_metric='rmse',\n                       verbose=False,\n                       early_stopping_rounds=20\n                       )\n\n        # modelf = lgb.LGBMClassifier(**lgb_f_params)\n        # remove param eval_metric='multi_logloss', for xgb\n        modelf = xgb.XGBClassifier(**xgb_f_params)\n        with timer(\"fit F\"):\n            modelf.fit(X_train, y_trainf,\n                       eval_set=[(X_valid, y_validf)],\n                       eval_metric='mlogloss', #for xgboot\n                       verbose=False,\n                       early_stopping_rounds=20\n                       )\n\n        oof_x[val_idx] = modelx.predict(X_valid)\n        oof_y[val_idx] = modely.predict(X_valid)\n        oof_f[val_idx] = modelf.predict(X_valid).astype(int)\n\n        preds_x += modelx.predict(test_data.iloc[:, :-1]) / N_SPLITS\n        preds_y += modely.predict(test_data.iloc[:, :-1]) / N_SPLITS\n        preds_f_arr[:, fold] = modelf.predict(test_data.iloc[:, :-1]).astype(int)\n\n        score = comp_metric(oof_x[val_idx], oof_y[val_idx], oof_f[val_idx],\n                            y_validx.to_numpy(), y_validy.to_numpy(), y_validf.to_numpy())\n        print(f\"fold {fold}: mean position error {score}\")\n        score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, fold, SEED, score)\n\n    print(\"*+\"*40)\n    print(f\"file #{n_files}, shape={data.shape}, name={os.path.basename(file)}\")\n    score = comp_metric(oof_x, oof_y, oof_f,\n                        data.iloc[:, -4].to_numpy(), data.iloc[:, -3].to_numpy(), data.iloc[:, -2].to_numpy())\n    oof.append(score)\n    print(f\"mean position error {score}\")\n    print(\"*+\"*40)\n    score_df = score_log(score_df, n_files, os.path.basename(file), data.shape, 999, SEED, score)\n\n    preds_f_mode = stats.mode(preds_f_arr, axis=1)\n    preds_f = preds_f_mode[0].astype(int).reshape(-1)\n    test_preds = pd.DataFrame(np.stack((preds_f, preds_x, preds_y))).T\n    test_preds.columns = subm.columns\n    test_preds.index = test_data[\"site_path_timestamp\"]\n    test_preds[\"floor\"] = test_preds[\"floor\"].astype(int)\n    predictions.append(test_preds)\n\n# ------------------------------------------------------------------------------\n# Submit the result\n# ------------------------------------------------------------------------------\nall_preds = pd.concat(predictions)\nall_preds = all_preds.reindex(subm.index)\nall_preds.to_csv('submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}